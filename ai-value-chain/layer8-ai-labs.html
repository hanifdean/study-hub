<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Layer 8: AI Labs & Software ‚Äî AI Value Chain</title>
<style>
  @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');
  
  * { margin: 0; padding: 0; box-sizing: border-box; }
  :root {
    --bg: #0a0a0f;
    --surface: #111118;
    --surface-alt: #1a1a2e;
    --surface-hover: #1e1e2a;
    --border: #1e1e2e;
    --border-alt: #2a2a4a;
    --text: #e8e8ed;
    --text-secondary: #d1d5db;
    --text-muted: #9ca3af;
    --text-dim: #6b7280;
    --text-dimmer: #4b5563;
    --accent: #5ec4b6;
    --accent-light: #34d399;
    --accent-glow: rgba(94, 196, 182, 0.12);
    --highlight-text: #fbbf24;
    --worth-accent: #a78bfa;
    --table-current-bg: rgba(94, 196, 182, 0.08);
    --table-current-text: #5ec4b6;
  }

  [data-theme="light"] {
    --bg: #f8f6f2;
    --surface: #ffffff;
    --surface-alt: #f5f3ef;
    --surface-hover: #faf8f5;
    --border: #e5e0d8;
    --border-alt: #d5d0c8;
    --text: #2c2a26;
    --text-secondary: #4a4640;
    --text-muted: #6b6560;
    --text-dim: #8a8580;
    --text-dimmer: #a5a09a;
    --accent: #1a8a7d;
    --accent-light: #059669;
    --accent-glow: rgba(26, 138, 125, 0.06);
    --highlight-text: #b45309;
    --worth-accent: #7c3aed;
    --table-current-bg: rgba(26, 138, 125, 0.08);
    --table-current-text: #1a8a7d;
  }

  
  body {
    font-family: 'Inter', -apple-system, sans-serif;
    background: var(--bg);
    color: var(--text);
    padding: 40px 24px;
    min-height: 100vh;
  
    transition: background 0.3s ease, color 0.3s ease;
  }
  
  .container {
    max-width: 1100px;
    margin: 0 auto;
  }
  
  h1 {
    font-size: 28px;
    font-weight: 800;
    margin-bottom: 6px;
    background: linear-gradient(135deg, #c084fc, #f472b6);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
  }
  
  .subtitle {
    font-size: 14px;
    color: var(--text-dim);
    margin-bottom: 36px;
    font-weight: 500;
  }
  
  .section-title {
    font-size: 18px;
    font-weight: 700;
    margin-bottom: 16px;
    display: flex;
    align-items: center;
    gap: 8px;
  }
  .section-title .emoji { font-size: 20px; }
  
  /* === BIG PICTURE === */
  .big-picture {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 16px;
    padding: 32px;
    margin-bottom: 32px;
    overflow-x: auto;
  }
  
  .flow-row {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0;
    flex-wrap: nowrap;
    min-width: 900px;
  }
  
  .flow-node {
    background: var(--surface-alt);
    border: 1.5px solid var(--border-alt);
    border-radius: 12px;
    padding: 14px 16px;
    text-align: center;
    min-width: 120px;
    flex-shrink: 0;
  }
  .flow-node .label { font-size: 11px; color: var(--text-muted); font-weight: 600; text-transform: uppercase; letter-spacing: 0.5px; }
  .flow-node .name { font-size: 14px; font-weight: 700; margin-top: 4px; }
  .flow-node.highlight {
    border-color: #c084fc;
    background: #1a102a;
    box-shadow: 0 0 24px rgba(192, 132, 252, 0.2);
  }
  .flow-node.highlight .name { color: #d8b4fe; }
  .flow-node.dim { opacity: 0.5; }
  
  .flow-arrow {
    font-size: 18px;
    color: var(--text-dimmer);
    padding: 0 6px;
    flex-shrink: 0;
  }
  
  /* === ANATOMY CARDS === */
  .anatomy-card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 16px;
    padding: 28px;
    margin-bottom: 32px;
  }
  
  .anatomy-card h3 {
    font-size: 16px;
    font-weight: 700;
    margin-bottom: 16px;
  }
  
  /* === LAB CARDS === */
  .lab-grid {
    display: flex;
    flex-direction: column;
    gap: 16px;
    margin: 16px 0;
  }
  
  .lab-card {
    background: var(--surface-alt);
    border: 1px solid var(--border-alt);
    border-radius: 12px;
    padding: 20px;
    display: grid;
    grid-template-columns: auto 1fr auto;
    gap: 16px;
    align-items: start;
  }
  
  .lab-icon {
    width: 48px;
    height: 48px;
    border-radius: 12px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 22px;
    flex-shrink: 0;
  }
  
  .lab-info .l-name {
    font-size: 15px;
    font-weight: 700;
    margin-bottom: 2px;
  }
  .lab-info .l-focus {
    font-size: 11px;
    color: var(--text-muted);
    font-weight: 600;
    margin-bottom: 8px;
  }
  .lab-info .l-desc {
    font-size: 12px;
    color: var(--text-secondary);
    line-height: 1.5;
  }
  
  .lab-val {
    text-align: right;
    flex-shrink: 0;
  }
  .lab-val .val-num {
    font-size: 22px;
    font-weight: 800;
  }
  .lab-val .val-label {
    font-size: 10px;
    color: var(--text-muted);
    margin-top: 2px;
  }
  
  .lab-card.openai { border-color: #10b981; }
  .lab-card.openai .lab-icon { background: linear-gradient(135deg, #064e3b, #10b981); border: 1.5px solid #34d399; }
  .lab-card.openai .l-name { color: #6ee7b7; }
  .lab-card.openai .val-num { color: #6ee7b7; }
  
  .lab-card.anthropic { border-color: #d4a574; }
  .lab-card.anthropic .lab-icon { background: linear-gradient(135deg, #451a03, #d4a574); border: 1.5px solid #d4a574; }
  .lab-card.anthropic .l-name { color: #d4a574; }
  .lab-card.anthropic .val-num { color: #d4a574; }
  
  .lab-card.deepmind { border-color: #3b82f6; }
  .lab-card.deepmind .lab-icon { background: linear-gradient(135deg, #1e3a5f, #3b82f6); border: 1.5px solid #60a5fa; }
  .lab-card.deepmind .l-name { color: #93c5fd; }
  .lab-card.deepmind .val-num { color: #93c5fd; }
  
  .lab-card.meta { border-color: #6366f1; }
  .lab-card.meta .lab-icon { background: linear-gradient(135deg, #312e81, #6366f1); border: 1.5px solid #818cf8; }
  .lab-card.meta .l-name { color: #a5b4fc; }
  .lab-card.meta .val-num { color: #a5b4fc; }
  
  .lab-card.xai { border-color: #f43f5e; }
  .lab-card.xai .lab-icon { background: linear-gradient(135deg, #4c0519, #f43f5e); border: 1.5px solid #fb7185; }
  .lab-card.xai .l-name { color: #fda4af; }
  .lab-card.xai .val-num { color: #fda4af; }
  
  /* === TRAINING VS INFERENCE === */
  .tvi-grid {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 0;
    margin: 16px 0;
    border-radius: 12px;
    overflow: hidden;
  }
  
  .tvi-side {
    padding: 24px;
    display: flex;
    flex-direction: column;
    gap: 12px;
  }
  .tvi-side.training {
    background: linear-gradient(135deg, #1a0f2e, #2e1065);
    border: 1px solid #7c3aed;
  }
  .tvi-side.inference {
    background: linear-gradient(135deg, #0f1a2e, #172554);
    border: 1px solid #3b82f6;
  }
  
  .tvi-header {
    font-size: 15px;
    font-weight: 700;
    display: flex;
    align-items: center;
    gap: 8px;
  }
  .tvi-analogy {
    font-size: 12px;
    font-weight: 600;
    opacity: 0.8;
  }
  .tvi-desc {
    font-size: 12px;
    opacity: 0.9;
    line-height: 1.5;
  }
  .tvi-stats {
    display: flex;
    flex-direction: column;
    gap: 6px;
    margin-top: auto;
  }
  .tvi-stat {
    font-size: 11px;
    font-weight: 600;
    display: flex;
    justify-content: space-between;
    padding: 6px 10px;
    background: rgba(0,0,0,0.2);
    border-radius: 6px;
  }
  
  .tvi-shift {
    background: var(--surface);
    border: 1px solid var(--border-alt);
    border-radius: 12px;
    padding: 20px;
    margin-top: 16px;
    text-align: center;
  }
  .tvi-shift .shift-label {
    font-size: 14px;
    font-weight: 700;
    color: #fbbf24;
    margin-bottom: 8px;
  }
  .tvi-shift .shift-desc {
    font-size: 12px;
    color: var(--text-secondary);
    line-height: 1.6;
  }
  
  /* === BREAKTHROUGHS === */
  .breakthrough-list {
    display: flex;
    flex-direction: column;
    gap: 0;
    margin: 16px 0;
    border-left: 2px solid #c084fc;
    padding-left: 20px;
  }
  
  .bt-item {
    position: relative;
    padding: 14px 0;
    border-bottom: 1px solid var(--border);
  }
  .bt-item:last-child { border-bottom: none; }
  .bt-item::before {
    content: '';
    position: absolute;
    left: -25px;
    top: 20px;
    width: 10px;
    height: 10px;
    border-radius: 50%;
    background: #c084fc;
    border: 2px solid var(--bg);
  }
  .bt-item .bt-name {
    font-size: 14px;
    font-weight: 700;
    color: #d8b4fe;
    margin-bottom: 4px;
  }
  .bt-item .bt-desc {
    font-size: 12px;
    color: var(--text-secondary);
    line-height: 1.5;
  }
  
  /* === OPEN VS CLOSED === */
  .ovc-grid {
    display: grid;
    grid-template-columns: 1fr auto 1fr;
    gap: 0;
    margin: 16px 0;
    align-items: stretch;
  }
  
  .ovc-side {
    border-radius: 12px;
    padding: 20px;
  }
  .ovc-side.open {
    background: linear-gradient(135deg, #0f2a1a, #14532d);
    border: 1px solid #22c55e;
  }
  .ovc-side.closed {
    background: linear-gradient(135deg, #2a0f1a, #4c1d95);
    border: 1px solid #a78bfa;
  }
  .ovc-side h4 {
    font-size: 14px;
    font-weight: 700;
    margin-bottom: 10px;
  }
  .ovc-side .ovc-models {
    list-style: none;
    padding: 0;
  }
  .ovc-side .ovc-models li {
    font-size: 12px;
    padding: 4px 0;
    font-weight: 500;
  }
  .ovc-side .ovc-pros {
    font-size: 11px;
    margin-top: 10px;
    padding-top: 10px;
    border-top: 1px solid rgba(255,255,255,0.1);
    line-height: 1.5;
  }
  
  .ovc-vs {
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 0 16px;
    font-size: 14px;
    font-weight: 800;
    color: var(--text-dim);
  }
  
  /* === SOFTWARE STACK === */
  .stack-layers {
    display: flex;
    flex-direction: column;
    gap: 0;
    margin: 16px 0;
  }
  
  .stack-layer {
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 14px 16px;
    border: 1px solid var(--border-alt);
    margin-bottom: -1px;
  }
  .stack-layer:first-child { border-radius: 12px 12px 0 0; }
  .stack-layer:last-child { border-radius: 0 0 12px 12px; }
  
  .stack-layer .sl-label {
    width: 120px;
    font-size: 11px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    flex-shrink: 0;
  }
  .stack-layer .sl-items {
    font-size: 12px;
    color: var(--text-secondary);
    font-weight: 500;
  }
  
  .stack-layer.l1 { background: linear-gradient(90deg, #1a0f2e, var(--surface)); }
  .stack-layer.l1 .sl-label { color: #d8b4fe; }
  .stack-layer.l2 { background: linear-gradient(90deg, #0f1a2e, var(--surface)); }
  .stack-layer.l2 .sl-label { color: #93c5fd; }
  .stack-layer.l3 { background: linear-gradient(90deg, #0f2a1a, var(--surface)); }
  .stack-layer.l3 .sl-label { color: #86efac; }
  .stack-layer.l4 { background: linear-gradient(90deg, #2a1a0f, var(--surface)); }
  .stack-layer.l4 .sl-label { color: #fde68a; }
  .stack-layer.l5 { background: linear-gradient(90deg, #2a0f1a, var(--surface)); }
  .stack-layer.l5 .sl-label { color: #fda4af; }
  
  /* === KEY NUMBERS === */
  .key-numbers {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 16px;
    margin: 24px 0;
  }
  
  .key-num {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 12px;
    padding: 20px;
    text-align: center;
  }
  
  .key-num .num {
    font-size: 28px;
    font-weight: 800;
    background: linear-gradient(135deg, #c084fc, #f472b6);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
  }
  
  .key-num .desc {
    font-size: 11px;
    color: var(--text-muted);
    margin-top: 6px;
    line-height: 1.4;
  }
  
  /* === WORTH KNOWING === */
  .worth-knowing {
    background: var(--surface);
    border: 1px solid var(--border-alt);
    border-left: 3px solid var(--worth-accent);
    border-radius: 0 12px 12px 0;
    padding: 24px;
    margin-top: 32px;
  }
  
  .worth-knowing h3 {
    font-size: 15px;
    font-weight: 700;
    color: var(--worth-accent);
    margin-bottom: 12px;
  }
  
  .worth-knowing ul {
    list-style: none;
    padding: 0;
  }
  
  .worth-knowing li {
    font-size: 13px;
    line-height: 1.6;
    padding: 6px 0;
    border-bottom: 1px solid var(--border);
    color: var(--text-secondary);
  }
  .worth-knowing li:last-child { border-bottom: none; }
  .worth-knowing li strong { color: var(--text); }
  
  /* === MOBILE RESPONSIVE === */
  @media (max-width: 600px) {
    body { padding: 20px 12px; font-size: 15px; }
    h1 { font-size: 22px; }
    .subtitle { font-size: 13px; margin-bottom: 24px; }
    .section-title { font-size: 16px; }
    
    .big-picture { padding: 20px 14px; overflow-x: visible; }
    .flow-row {
      min-width: auto;
      flex-direction: column;
      align-items: stretch;
      gap: 0;
    }
    .flow-node { min-width: auto; width: 100%; padding: 12px 14px; }
    .flow-node .name { font-size: 14px; }
    .flow-arrow {
      text-align: center;
      padding: 4px 0;
      font-size: 16px;
      transform: rotate(90deg);
    }
    
    .anatomy-card { padding: 20px 14px; }
    .anatomy-card h3 { font-size: 15px; }
    
    .lab-card {
      grid-template-columns: 1fr;
      gap: 10px;
    }
    .lab-icon { display: none; }
    .lab-val {
      text-align: left;
      display: flex;
      gap: 8px;
      align-items: baseline;
    }
    .lab-val .val-num { font-size: 18px; }
    
    .tvi-grid { grid-template-columns: 1fr; }
    .tvi-side { padding: 18px; }
    
    .ovc-grid { grid-template-columns: 1fr; gap: 12px; }
    .ovc-vs { padding: 8px 0; }
    
    .stack-layer { flex-direction: column; align-items: flex-start; gap: 4px; }
    .stack-layer .sl-label { width: auto; }
    
    .key-numbers { grid-template-columns: 1fr; gap: 12px; }
    .key-num { padding: 16px; }
    .key-num .num { font-size: 24px; }
    .key-num .desc { font-size: 12px; }
    
    .worth-knowing { padding: 20px 16px; }
    .worth-knowing li { font-size: 14px; line-height: 1.7; padding: 8px 0; }
    
    p { font-size: 14px; }
  }
  
  @media (max-width: 360px) {
    body { padding: 16px 8px; }
    .big-picture { padding: 16px 10px; }
    .anatomy-card { padding: 16px 10px; }
    .key-num .num { font-size: 22px; }
  }

  .top-bar {
    display: flex;
    align-items: center;
    justify-content: space-between;
    max-width: 1100px;
    margin: 0 auto 0;
    padding: 0 0 16px 0;
  }
  .back-link {
    font-size: 13px;
    color: var(--text-muted);
    text-decoration: none;
    display: flex;
    align-items: center;
    gap: 6px;
    transition: color 0.2s;
  }
  .back-link:hover { color: var(--accent); }
  .theme-toggle {
    background: none;
    border: 1.5px solid var(--border-alt);
    border-radius: 8px;
    padding: 6px 10px;
    cursor: pointer;
    font-size: 16px;
    color: var(--text-muted);
    transition: border-color 0.2s, color 0.2s;
  }
  .theme-toggle:hover { border-color: var(--accent); color: var(--accent); }

  /* Inline jargon links */
  .jargon {
    color: var(--accent);
    text-decoration: none;
    border-bottom: 1.5px dotted var(--accent);
    cursor: pointer;
    transition: color 0.2s, border-color 0.2s;
  }
  .jargon:hover {
    color: var(--teal, var(--accent-light, #2dd4bf));
    border-color: var(--teal, var(--accent-light, #2dd4bf));
  }
  .jargon-def {
    scroll-margin-top: 24px;
  }
  .jargon-def:target {
    outline: 2px solid var(--accent);
    outline-offset: 4px;
    border-radius: 10px;
    animation: jargon-flash 1.2s ease;
  }
  @keyframes jargon-flash {
    0%, 100% { outline-color: transparent; }
    20%, 80% { outline-color: var(--accent); }
  }
  .jargon-back {
    font-size: 11px;
    color: var(--muted, var(--text-muted, #9ca3af));
    text-decoration: none;
    margin-left: 6px;
    opacity: 0.7;
    transition: opacity 0.2s, color 0.2s;
  }
  .jargon-back:hover { opacity: 1; color: var(--accent); }
</style>
</head>
<body>
<div class="container">
<div class="top-bar">
  <a href="../" class="back-link">‚Üê Back to Study Hub</a>
  <button class="theme-toggle" onclick="toggleTheme()" title="Toggle light/dark mode">
    <span id="theme-icon">‚òÄÔ∏è</span>
  </button>
</div>


  <h1>üß™ Layer 8: AI Labs & Software</h1>
  <p class="subtitle">The top of the stack ‚Äî companies building and deploying AI models that are reshaping the world</p>

  <!-- ========== 1. WHERE THIS SITS ========== -->
  <div class="big-picture">
    <div class="section-title"><span class="emoji">üó∫Ô∏è</span> Where This Sits in the AI Value Chain</div>
    <p style="font-size:13px;color:var(--text-muted);margin-bottom:16px;">Layer 8 is <strong style="color:#d8b4fe;">where everything converges</strong>. All the sand, silicon, lithography, memory, processors, servers, and cloud compute ‚Äî it all exists to serve this layer. AI labs consume massive amounts of compute to train and deploy models that generate intelligence. This is where the value chain produces its ultimate output.</p>
    <div class="flow-row">
      <div class="flow-node dim"><div class="label">Layer 1-3</div><div class="name">Materials ‚Üí Fab</div></div>
      <div class="flow-arrow">‚Üí</div>
      <div class="flow-node dim"><div class="label">Layer 4-5</div><div class="name">Memory ‚Üí Chips</div></div>
      <div class="flow-arrow">‚Üí</div>
      <div class="flow-node dim"><div class="label">Layer 6</div><div class="name">Servers & Infra</div></div>
      <div class="flow-arrow">‚Üí</div>
      <div class="flow-node dim"><div class="label">Layer 7</div><div class="name">Cloud & Compute</div></div>
      <div class="flow-arrow">‚Üí</div>
      <div class="flow-node highlight"><div class="label">Layer 8</div><div class="name">üß™ AI Labs & Software</div></div>
      <div class="flow-arrow">‚Üí</div>
      <div class="flow-node dim"><div class="label">Layer 9</div><div class="name">AI Apps</div></div>
    </div>
  </div>

  <!-- ========== 2. FRONTIER LABS ========== -->
  <div class="anatomy-card">
    <h3>üèÜ The Frontier Labs Landscape</h3>
    <p style="font-size:13px;color:var(--text-muted);margin-bottom:16px;">Five labs are racing to build the most capable AI models in the world. Each has a different strategy, different backers, and different philosophies about how AI should be developed.</p>
    
    <div class="lab-grid">
      <div class="lab-card openai">
        <div class="lab-icon">üü¢</div>
        <div class="lab-info">
          <div class="l-name">OpenAI</div>
          <div class="l-focus">GPT-5 ¬∑ o-series reasoning models ¬∑ Codex ¬∑ ChatGPT</div>
          <div class="l-desc">The company that started the AI arms race. GPT-4 changed the world, and GPT-5 aims to push further. Their o-series models (o1, o3, o4-mini) introduced "reasoning" ‚Äî models that think step-by-step before answering. Codex agent writes and executes code autonomously. Exclusive partnership with Microsoft (Azure runs all OpenAI inference).</div>
        </div>
        <div class="lab-val">
          <div class="val-num">$157B</div>
          <div class="val-label">Valuation</div>
        </div>
      </div>
      
      <div class="lab-card anthropic">
        <div class="lab-icon">üü§</div>
        <div class="lab-info">
          <div class="l-name">Anthropic</div>
          <div class="l-focus">Claude ¬∑ Opus 4.5 ¬∑ Constitutional AI ¬∑ Safety-first</div>
          <div class="l-desc">Founded by ex-OpenAI researchers who wanted a safety-focused approach. Claude models are known for being thoughtful, honest, and excellent at coding. Opus 4.5 is the most capable coding model available. Pioneered Constitutional AI ‚Äî training models to follow principles rather than just instructions. Amazon partnership ($8B+ investment).</div>
        </div>
        <div class="lab-val">
          <div class="val-num">$60B</div>
          <div class="val-label">Valuation</div>
        </div>
      </div>
      
      <div class="lab-card deepmind">
        <div class="lab-icon">üîµ</div>
        <div class="lab-info">
          <div class="l-name">Google DeepMind</div>
          <div class="l-focus">Gemini 2.0 ¬∑ TPU advantage ¬∑ Google integration</div>
          <div class="l-desc">Merged Google Brain + DeepMind into one powerhouse. Gemini 2.0 is competitive with GPT-4. Unique advantage: builds on Google's custom TPU chips (no dependence on Nvidia). AI integrated across Search, Gmail, Docs, YouTube. Also leads in AI for science (AlphaFold for protein structure, weather prediction).</div>
        </div>
        <div class="lab-val">
          <div class="val-num">$2T+</div>
          <div class="val-label">Alphabet mktcap</div>
        </div>
      </div>
      
      <div class="lab-card meta">
        <div class="lab-icon">üîÆ</div>
        <div class="lab-info">
          <div class="l-name">Meta AI</div>
          <div class="l-focus">Llama (<a href="#jargon-open-source" class="jargon">open source</a>) ¬∑ Largest open model ecosystem</div>
          <div class="l-desc">Meta's bet: give away the models for free, make the ecosystem dependent on your platform. Llama 3 and 4 are the most widely used <a href="#jargon-open-source" class="jargon">open-source</a> AI models in the world. This undercuts competitors' revenue while Meta benefits from AI across Instagram, Facebook, WhatsApp, and Ray-Ban Meta glasses.</div>
        </div>
        <div class="lab-val">
          <div class="val-num">Open</div>
          <div class="val-label">Source strategy</div>
        </div>
      </div>
      
      <div class="lab-card xai">
        <div class="lab-icon">‚úñÔ∏è</div>
        <div class="lab-info">
          <div class="l-name">xAI</div>
          <div class="l-focus">Grok ¬∑ Memphis supercluster ¬∑ Colossus</div>
          <div class="l-desc">Elon Musk's AI lab, moving at breakneck speed. Built "Colossus" ‚Äî one of the world's largest GPU clusters (100,000+ H100s) in Memphis in under 4 months. Grok models power X (Twitter) and are catching up to frontier labs. Access to real-time X data is a unique training advantage.</div>
        </div>
        <div class="lab-val">
          <div class="val-num">$50B+</div>
          <div class="val-label">Valuation</div>
        </div>
      </div>
    </div>
  </div>

  <!-- ========== 3. TRAINING VS INFERENCE ========== -->
  <div class="anatomy-card">
    <h3>üß† Training vs Inference ‚Äî The Two Phases of AI</h3>
    <p style="font-size:13px;color:var(--text-muted);margin-bottom:16px;">Every AI model has two distinct phases of its lifecycle. Understanding the difference is key to understanding AI economics.</p>
    
    <div class="tvi-grid">
      <div class="tvi-side training">
        <div class="tvi-header" style="color:#d8b4fe;">üèóÔ∏è Training</div>
        <div class="tvi-analogy" style="color:#c4b5fd;">= Building the brain</div>
        <div class="tvi-desc" style="color:#e9d5ff;">Teaching the model by processing trillions of tokens of text, code, and data. The model learns patterns, facts, reasoning. This happens once (per model version) and is astronomically expensive.</div>
        <div class="tvi-stats">
          <div class="tvi-stat" style="color:#d8b4fe;"><span>Cost</span><span>$100M ‚Äì $1B+</span></div>
          <div class="tvi-stat" style="color:#d8b4fe;"><span>Duration</span><span>Months of compute</span></div>
          <div class="tvi-stat" style="color:#d8b4fe;"><span>GPUs needed</span><span>10,000 ‚Äì 100,000+</span></div>
          <div class="tvi-stat" style="color:#d8b4fe;"><span>Frequency</span><span>Once per model version</span></div>
        </div>
      </div>
      <div class="tvi-side inference">
        <div class="tvi-header" style="color:#93c5fd;">‚ö° Inference</div>
        <div class="tvi-analogy" style="color:#bfdbfe;">= Using the brain</div>
        <div class="tvi-desc" style="color:#dbeafe;">Running the trained model to generate responses for users. Every ChatGPT answer, every Claude response, every Gemini search result is an inference call. This is ongoing, scales with users, and is where the money is made.</div>
        <div class="tvi-stats">
          <div class="tvi-stat" style="color:#93c5fd;"><span>Cost per query</span><span>$0.001 ‚Äì $0.10</span></div>
          <div class="tvi-stat" style="color:#93c5fd;"><span>Duration</span><span>Seconds per response</span></div>
          <div class="tvi-stat" style="color:#93c5fd;"><span>Scale</span><span>Millions of calls/day</span></div>
          <div class="tvi-stat" style="color:#93c5fd;"><span>Frequency</span><span>24/7, forever</span></div>
        </div>
      </div>
    </div>
    
    <div class="tvi-shift">
      <div class="shift-label">üìà The Big Shift: Inference Is Exploding</div>
      <div class="shift-desc">Training was the bottleneck in 2022-2023 ‚Äî labs couldn't get enough GPUs to train new models. But now, as AI gets deployed to hundreds of millions of users, <strong>inference demand is exploding</strong>. ChatGPT alone serves 400M+ weekly users. Every query requires GPU compute. Nvidia's Blackwell architecture is specifically designed for this shift ‚Äî optimized for inference throughput, not just training speed.</div>
    </div>
  </div>

  <!-- ========== 4. KEY BREAKTHROUGHS ========== -->
  <div class="anatomy-card">
    <h3>üî¨ Key Breakthroughs That Made Current AI Possible</h3>
    <p style="font-size:13px;color:var(--text-muted);margin-bottom:8px;">The AI revolution didn't happen overnight. It was built on a series of interconnected breakthroughs, each enabling the next:</p>
    
    <div class="breakthrough-list">
      <div class="bt-item">
        <div class="bt-name">üìê Scaling Laws (2020)</div>
        <div class="bt-desc">OpenAI discovered that model performance improves <em>predictably</em> as you increase compute, data, and <a href="#jargon-parameters" class="jargon">parameters</a>. This meant you could plan investments ‚Äî spend 10√ó more compute, get a reliably better model. This kicked off the GPU arms race because labs could justify billions in spending with predictable returns.</div>
      </div>
      <div class="bt-item">
        <div class="bt-name">üîÑ <a href="#jargon-transformer" class="jargon">Transformer</a> Architecture (2017)</div>
        <div class="bt-desc">Google's "Attention Is All You Need" paper introduced the <a href="#jargon-transformer" class="jargon">transformer</a> ‚Äî a neural network architecture that processes all input tokens in parallel (not sequentially). This made training massively parallelizable across thousands of GPUs. Every major AI model today (GPT, Claude, Gemini, Llama) is a <a href="#jargon-transformer" class="jargon">transformer</a>.</div>
      </div>
      <div class="bt-item">
        <div class="bt-name">üéØ <a href="#jargon-rlhf" class="jargon">RLHF</a> & Constitutional AI (2022-2023)</div>
        <div class="bt-desc">Reinforcement Learning from Human Feedback (<a href="#jargon-rlhf" class="jargon">RLHF</a>) taught models to follow instructions and be helpful. Anthropic's Constitutional AI went further ‚Äî training models to follow a set of principles (be honest, avoid harm) rather than just mimicking human preferences. These techniques turned raw language models into useful assistants.</div>
      </div>
      <div class="bt-item">
        <div class="bt-name">üí≠ Chain-of-Thought & Reasoning (2024-2025)</div>
        <div class="bt-desc">OpenAI's o-series and similar models introduced "test-time compute" ‚Äî models that spend more time thinking before answering. Instead of generating instant responses, they reason step-by-step, catching errors and exploring different approaches. This dramatically improved performance on math, coding, and complex problems.</div>
      </div>
      <div class="bt-item">
        <div class="bt-name">ü§ñ Agentic Capabilities (2025)</div>
        <div class="bt-desc">Models that can use tools, write and execute code, browse the web, and complete multi-step tasks autonomously. Anthropic's Claude can use computers. OpenAI's Codex writes code in sandboxes. This is the current frontier ‚Äî AI that doesn't just answer questions but takes actions in the real world.</div>
      </div>
    </div>
  </div>

  <!-- ========== 5. OPEN SOURCE VS CLOSED ========== -->
  <div class="anatomy-card">
    <h3>‚öñÔ∏è Open Source vs Closed ‚Äî The Great AI Debate</h3>
    <p style="font-size:13px;color:var(--text-muted);margin-bottom:16px;">One of the most consequential debates in AI: should powerful models be released openly, or kept behind APIs?</p>
    
    <div class="ovc-grid">
      <div class="ovc-side open">
        <h4 style="color:#4ade80;">üîì Open Source / Open Weight</h4>
        <ul class="ovc-models" style="color:#bbf7d0;">
          <li>ü¶ô <strong>Llama 3/4</strong> (Meta)</li>
          <li>üå¨Ô∏è <strong>Mistral Large</strong> (Mistral AI)</li>
          <li>üîç <strong>DeepSeek V3/R1</strong> (DeepSeek)</li>
          <li>ü§ó <strong>Qwen 2.5</strong> (Alibaba)</li>
        </ul>
        <div class="ovc-pros" style="color:#86efac;">
          <strong>Arguments for:</strong> Democratizes AI access. Enables innovation. Prevents monopoly. You can run it on your own hardware. Community improves models. Transparency builds trust.
        </div>
      </div>
      
      <div class="ovc-vs">VS</div>
      
      <div class="ovc-side closed">
        <h4 style="color:#d8b4fe;">üîí Closed / API-only</h4>
        <ul class="ovc-models" style="color:#e9d5ff;">
          <li>üü¢ <strong>GPT-5 / o3</strong> (OpenAI)</li>
          <li>üü§ <strong>Claude Opus 4.5</strong> (Anthropic)</li>
          <li>üîµ <strong>Gemini 2.0 Ultra</strong> (Google)</li>
          <li>‚úñÔ∏è <strong>Grok 3</strong> (xAI)</li>
        </ul>
        <div class="ovc-pros" style="color:#c4b5fd;">
          <strong>Arguments for:</strong> Safety controls. Prevents misuse. Funds continued research. Can implement guardrails. Better alignment. Revenue model enables more R&D.
        </div>
      </div>
    </div>
    
    <p style="font-size:12px;color:#fbbf24;text-align:center;margin-top:16px;font-weight:600;">
      The real debate isn't open vs closed ‚Äî it's safety vs accessibility. Both sides have valid points.
    </p>
  </div>

  <!-- ========== 6. AI SOFTWARE STACK ========== -->
  <div class="anatomy-card">
    <h3>üß± The AI Software Stack</h3>
    <p style="font-size:13px;color:var(--text-muted);margin-bottom:16px;">AI isn't just models ‚Äî it's an entire software ecosystem. Here's how the layers stack up:</p>
    
    <div class="stack-layers">
      <div class="stack-layer l1">
        <div class="sl-label">Applications</div>
        <div class="sl-items">ChatGPT ¬∑ Claude.ai ¬∑ Gemini ¬∑ Copilot ¬∑ Perplexity ¬∑ Cursor ¬∑ Midjourney</div>
      </div>
      <div class="stack-layer l2">
        <div class="sl-label">Orchestration</div>
        <div class="sl-items">LangChain ¬∑ LlamaIndex ¬∑ CrewAI ¬∑ AutoGen ¬∑ Semantic Kernel</div>
      </div>
      <div class="stack-layer l3">
        <div class="sl-label">Inference Engines</div>
        <div class="sl-items">vLLM ¬∑ TensorRT-<a href="#jargon-llm" class="jargon">LLM</a> (Nvidia) ¬∑ Triton ¬∑ ONNX Runtime ¬∑ llama.cpp</div>
      </div>
      <div class="stack-layer l4">
        <div class="sl-label">Frameworks</div>
        <div class="sl-items">PyTorch (Meta) ¬∑ JAX (Google) ¬∑ TensorFlow ¬∑ Hugging Face Transformers</div>
      </div>
      <div class="stack-layer l5">
        <div class="sl-label">GPU Software</div>
        <div class="sl-items">CUDA (Nvidia) ¬∑ ROCm (AMD) ¬∑ oneAPI (Intel) ¬∑ Metal (Apple) ¬∑ XLA (Google TPU)</div>
      </div>
    </div>
    
    <p style="font-size:12px;color:var(--text-secondary);margin-top:12px;line-height:1.6;text-align:center;">
      <strong>Key insight:</strong> PyTorch + CUDA is the dominant combination. This is a huge part of Nvidia's moat ‚Äî the entire AI software ecosystem is built on their platform.
    </p>
  </div>

  <!-- ========== 7. KEY NUMBERS ========== -->
  <div class="section-title"><span class="emoji">üî¢</span> Key Numbers to Remember</div>
  <div class="key-numbers">
    <div class="key-num">
      <div class="num">$500M+</div>
      <div class="desc">Estimated cost to train GPT-5 ‚Äî and costs keep rising with each generation</div>
    </div>
    <div class="key-num">
      <div class="num">$157B</div>
      <div class="desc">OpenAI's valuation ‚Äî the most valuable private company in AI</div>
    </div>
    <div class="key-num">
      <div class="num">400M+</div>
      <div class="desc">ChatGPT weekly active users ‚Äî inference demand is massive</div>
    </div>
    <div class="key-num">
      <div class="num">Opus 4.5</div>
      <div class="desc">Anthropic's coding breakthrough ‚Äî best-in-class for software engineering tasks</div>
    </div>
    <div class="key-num">
      <div class="num">1-2 yrs</div>
      <div class="desc">Dario Amodei's estimate for "powerful AI" ‚Äî timeline is compressing rapidly</div>
    </div>
    <div class="key-num">
      <div class="num">100K+</div>
      <div class="desc">H100 GPUs in xAI's Colossus cluster ‚Äî built in under 4 months</div>
    </div>
  </div>

  <!-- ========== 8. WORTH KNOWING ========== -->
  
  <!-- JARGON DECODER -->
  <div class="anatomy-card" style="margin-bottom:32px;">
    <h3>üìñ Jargon Decoder</h3>
    <div style="display:flex;flex-direction:column;gap:8px;margin-top:12px;">
        <div id="jargon-llm" class="jargon-def" style="padding:10px;background:var(--surface-alt, var(--surface-2, #1a1a2e));border-radius:10px;">
          <p style="font-size:13px;"><strong style="color:var(--accent);">LLM (Large Language Model)</strong> <a href="#" class="jargon-back" onclick="history.back();return false;">‚Ü© back</a></p>
          <p style="font-size:12px;color:var(--text-muted, var(--muted, #9ca3af));margin-top:4px;">AI models trained on massive text datasets that can generate, understand, and reason about language. GPT-4, Claude, and Gemini are LLMs.</p>
        </div>
        <div id="jargon-parameters" class="jargon-def" style="padding:10px;background:var(--surface-alt, var(--surface-2, #1a1a2e));border-radius:10px;">
          <p style="font-size:13px;"><strong style="color:var(--accent);">Parameters</strong> <a href="#" class="jargon-back" onclick="history.back();return false;">‚Ü© back</a></p>
          <p style="font-size:12px;color:var(--text-muted, var(--muted, #9ca3af));margin-top:4px;">The numerical values a model learns during training. More parameters generally = more capability. GPT-4 is estimated at ~1.8 trillion parameters.</p>
        </div>
        <div id="jargon-transformer" class="jargon-def" style="padding:10px;background:var(--surface-alt, var(--surface-2, #1a1a2e));border-radius:10px;">
          <p style="font-size:13px;"><strong style="color:var(--accent);">Transformer</strong> <a href="#" class="jargon-back" onclick="history.back();return false;">‚Ü© back</a></p>
          <p style="font-size:12px;color:var(--text-muted, var(--muted, #9ca3af));margin-top:4px;">The neural network architecture behind modern AI. Invented by Google in 2017 ("Attention Is All You Need"), it enables models to process sequences in parallel.</p>
        </div>
        <div id="jargon-fine-tuning" class="jargon-def" style="padding:10px;background:var(--surface-alt, var(--surface-2, #1a1a2e));border-radius:10px;">
          <p style="font-size:13px;"><strong style="color:var(--accent);">Fine-tuning</strong> <a href="#" class="jargon-back" onclick="history.back();return false;">‚Ü© back</a></p>
          <p style="font-size:12px;color:var(--text-muted, var(--muted, #9ca3af));margin-top:4px;">Taking a pre-trained model and further training it on specialized data for a specific task, much cheaper than training from scratch.</p>
        </div>
        <div id="jargon-rlhf" class="jargon-def" style="padding:10px;background:var(--surface-alt, var(--surface-2, #1a1a2e));border-radius:10px;">
          <p style="font-size:13px;"><strong style="color:var(--accent);">RLHF (Reinforcement Learning from Human Feedback)</strong> <a href="#" class="jargon-back" onclick="history.back();return false;">‚Ü© back</a></p>
          <p style="font-size:12px;color:var(--text-muted, var(--muted, #9ca3af));margin-top:4px;">A training technique where human evaluators rate AI outputs, and the model learns to produce responses humans prefer. Key to making LLMs helpful and safe.</p>
        </div>
        <div id="jargon-scaling-laws" class="jargon-def" style="padding:10px;background:var(--surface-alt, var(--surface-2, #1a1a2e));border-radius:10px;">
          <p style="font-size:13px;"><strong style="color:var(--accent);">Scaling Laws</strong> <a href="#" class="jargon-back" onclick="history.back();return false;">‚Ü© back</a></p>
          <p style="font-size:12px;color:var(--text-muted, var(--muted, #9ca3af));margin-top:4px;">The empirical observation that AI model performance improves predictably as you increase compute, data, and parameters. Drives the "bigger is better" arms race.</p>
        </div>
        <div id="jargon-open-source" class="jargon-def" style="padding:10px;background:var(--surface-alt, var(--surface-2, #1a1a2e));border-radius:10px;">
          <p style="font-size:13px;"><strong style="color:var(--accent);">Open Source (AI)</strong> <a href="#" class="jargon-back" onclick="history.back();return false;">‚Ü© back</a></p>
          <p style="font-size:12px;color:var(--text-muted, var(--muted, #9ca3af));margin-top:4px;">AI models whose weights and code are publicly released (e.g., Meta's LLaMA). Enables broad access but raises safety and competitive concerns.</p>
        </div>
        <div id="jargon-agi" class="jargon-def" style="padding:10px;background:var(--surface-alt, var(--surface-2, #1a1a2e));border-radius:10px;">
          <p style="font-size:13px;"><strong style="color:var(--accent);">AGI (Artificial General Intelligence)</strong> <a href="#" class="jargon-back" onclick="history.back();return false;">‚Ü© back</a></p>
          <p style="font-size:12px;color:var(--text-muted, var(--muted, #9ca3af));margin-top:4px;">A hypothetical AI system that matches or exceeds human-level intelligence across all domains. The stated goal of OpenAI and others.</p>
        </div>
    </div>
  </div>

  <div class="worth-knowing">
    <h3>üìå Worth Knowing</h3>
    <ul>
      <li><strong>The feedback loop</strong> ‚Äî AI is now writing code that builds better AI. Anthropic's Claude and OpenAI's Codex are used internally by AI labs to accelerate their own research. This creates a compounding cycle: better models ‚Üí faster research ‚Üí even better models. This is why timelines keep shrinking ‚Äî each generation of AI helps build the next one faster.</li>
      <li><strong>Inference costs will determine AI accessibility</strong> ‚Äî Training a model is a one-time cost. But serving it to millions of users costs money for every single query. If inference stays expensive, AI remains a tool for rich companies and countries. If it gets cheap (through better hardware, better algorithms, or smaller models), AI becomes truly universal. The cost curve is plummeting ‚Äî GPT-4-level performance that cost $30/million tokens in 2023 now costs ~$0.50.</li>
      <li><strong>DeepSeek showed you don't always need the most compute</strong> ‚Äî China's DeepSeek built competitive models (DeepSeek V3, R1) using significantly less compute than OpenAI or Google. They used clever algorithmic innovations (MoE architecture, efficient training) to punch above their weight. This challenged the "just throw more GPUs at it" narrative and showed that algorithmic efficiency matters as much as raw compute.</li>
      <li><strong>The open vs closed debate is really about safety vs accessibility</strong> ‚Äî Closed-model advocates (Anthropic, OpenAI) argue that powerful AI needs safety guardrails that only API access can enforce. Open-model advocates (Meta, Mistral) argue that transparency and community oversight are the real path to safety. Both have valid points ‚Äî the truth is likely some hybrid approach where certain capabilities are open and others are restricted.</li>
      <li><strong>The AI lab business model is unsustainable ‚Äî for now</strong> ‚Äî OpenAI reportedly loses money on ChatGPT subscriptions (inference costs exceed revenue per user). The bet is that costs will fall faster than revenue grows. If they don't, the current AI boom could face a reckoning similar to the dot-com bust. But if inference costs keep dropping at the current rate, AI becomes the most profitable business ever built.</li>
    </ul>
  </div>

</div>
<script>
function toggleTheme() {
  const html = document.documentElement;
  const current = html.getAttribute('data-theme');
  const next = current === 'dark' ? 'light' : 'dark';
  html.setAttribute('data-theme', next);
  document.getElementById('theme-icon').textContent = next === 'dark' ? '‚òÄÔ∏è' : 'üåô';
  localStorage.setItem('theme', next);
}
(function() {
  const saved = localStorage.getItem('theme');
  if (saved) {
    document.documentElement.setAttribute('data-theme', saved);
    document.addEventListener('DOMContentLoaded', () => {
      const icon = document.getElementById('theme-icon');
      if (icon) icon.textContent = saved === 'dark' ? '‚òÄÔ∏è' : 'üåô';
    });
  }
})();
</script>
</body>
</html>
